{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bit9e52c3456dfd47b1b3ac7d2ef85a63b2",
   "display_name": "Python 3.8.5 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.ndimage import rotate\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "import ransac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class image_processor:\n",
    "    equirec_i = np.load('/home/shane/stitching/image_processing/equirec_i_0.npy')\n",
    "    equirec_j = np.load('/home/shane/stitching/image_processing/equirec_j_0.npy')\n",
    "\n",
    "    circular_i = np.load('/home/shane/stitching/image_processing/circular_i.npy')\n",
    "    circular_j = np.load('/home/shane/stitching/image_processing/circular_j.npy')\n",
    "\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    def __init__(self, image):\n",
    "        self.img = image\n",
    "        self.spherical_img = self.to_spherical(image)\n",
    "        self.circular_img = self.to_circular(self.spherical_img)\n",
    "\n",
    "    def to_spherical(self, img):\n",
    "        return img[self.equirec_i, self.equirec_j]\n",
    "\n",
    "    def to_circular(self, spherical_img):\n",
    "        return spherical_img[self.circular_i, self.circular_j]\n",
    "        \n",
    "    def get_features(self):\n",
    "        grayscale_img = cv2.cvtColor(self.circular_img, cv2.COLOR_BGR2GRAY)\n",
    "        kp, des = self.sift.detectAndCompute(grayscale_img, None)\n",
    "        return kp, des\n",
    "\n",
    "    def show_features(self):\n",
    "        circular_img = np.copy(self.circular_img)\n",
    "        grayscale_img = cv2.cvtColor(self.circular_img, cv2.COLOR_BGR2GRAY)\n",
    "        kp, des = self.get_features()\n",
    "\n",
    "        circular_img=cv2.drawKeypoints(grayscale_img, kp, circular_img, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "        cv2.imshow('Features', circular_img)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_estimator:    \n",
    "    def transform_point(self, points, matrix):\n",
    "        new_points = cv2.transform(points.T[:, :, np.newaxis].T, matrix)[0].T\n",
    "        new_points = np.divide(new_points, new_points[2]).astype(int)\n",
    "        return new_points[:2].T\n",
    "\n",
    "    def fit(self, data):\n",
    "        data = data[0:4]\n",
    "        pts1 = np.float32(data[:, 0])\n",
    "        pts2 = np.float32(data[:, 1])\n",
    "        return cv2.getPerspectiveTransform(pts2, pts1)\n",
    "\n",
    "    def get_error(self, data, model):\n",
    "        center = data[:, 0]\n",
    "        right = self.transform_point(data[:, 1], model)\n",
    "\n",
    "        return np.linalg.norm(center - right, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks=50)   # or pass empty dictionary\n",
    "\n",
    "class image_combiner:\n",
    "    flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "    estimator = model_estimator()\n",
    "\n",
    "    def __init__(self, image0, image1):\n",
    "        self.ip0 = image_processor(image0)\n",
    "        self.ip1 = image_processor(image1)\n",
    "\n",
    "    def match_features(self):\n",
    "        kp_query, des_query = self.ip0.get_features()\n",
    "        kp_train, des_train = self.ip1.get_features()\n",
    "\n",
    "        matches = self.flann.knnMatch(des_query, des_train, k=2)\n",
    "        query_pixels, train_pixels = zip(*[(kp_query[m.queryIdx].pt, kp_train[m.trainIdx].pt) for (m, n) in matches if m.distance < 0.5 * n.distance])\n",
    "        kp = [m for (m, n) in matches if m.distance < 0.6 * n.distance]\n",
    "        return np.stack((query_pixels, train_pixels), axis=1), kp\n",
    "\n",
    "    def estimate_model(self):\n",
    "        matches = self.match_features()\n",
    "        return ransac.ransac(matches, self.estimator, 4, 100, 10, len(matches)*0.75, debug=False)\n",
    "\n",
    "    def combine(self):\n",
    "        matrix = self.estimate_model()\n",
    "        img2 = cv2.warpPerspective(self.ip1.circular_img, matrix, (1280, 1280))\n",
    "        img1 = self.ip0.circular_img\n",
    "\n",
    "        combine_img = np.zeros((1280, 1280, 3), np.uint8) \n",
    "        mask = np.all(img1 <= [5,5,5], axis=2)\n",
    "        combine_img[np.invert(mask)] = img1[np.invert(mask)]\n",
    "        combine_img[mask] = img2[mask]\n",
    "        \n",
    "        # dst = cv2.addWeighted(img1, 0.5, img2, 0.5, 0)\n",
    "        img2[mask] = [0,0,0]\n",
    "        cv2.imshow('Features', combine_img)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img0 = cv2.imread('/home/shane/camera0.jpg')\n",
    "# img1 = cv2.imread('/home/shane/camera1.jpg')\n",
    "img2 = cv2.imread('/home/shane/camera2.jpg')\n",
    "# img3 = cv2.imread('/home/shane/camera3.jpg')\n",
    "img4 = cv2.imread('/home/shane/camera4.jpg')\n",
    "\n",
    "ip0 = image_processor(img0)\n",
    "# ip1 = image_processor(img1)\n",
    "ip2 = image_processor(img2)\n",
    "# ip3 = image_processor(img3)\n",
    "ip4 = image_processor(img4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('/home/shane/camera0_cir.jpg', ip2.circular_img[210: 1070, 210:1070])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Features', ip2.circular_img[210: 1070, 210:1070])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic02 = image_combiner(img0, img2)\n",
    "kp1, _ = ip0.get_features()\n",
    "_, matches = ic02.match_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp1_matched = []\n",
    "for i in range(len(matches)):\n",
    "    index = matches[i].queryIdx\n",
    "    kp = kp1[index]\n",
    "    kp1_matched.append(kp)\n",
    "\n",
    "img_bla = ip0.circular_img\n",
    "cv2.drawKeypoints(img_bla, kp1_matched, img_bla, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "cv2.imshow('Features', img_bla)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ]
}